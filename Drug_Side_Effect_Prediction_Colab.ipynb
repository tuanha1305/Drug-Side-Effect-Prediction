{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üß¨ Drug Side Effect Prediction with Transformers\n",
    "\n",
    "**Complete pipeline for training and evaluating drug side effect prediction model**\n",
    "\n",
    "- üöÄ PyTorch 2.x optimizations (AMP, torch.compile, Flash Attention)\n",
    "- üìä 10-fold cross-validation\n",
    "- üìà Comprehensive metrics (RMSE, AUC-ROC, Pearson, etc.)\n",
    "- ‚ö° GPU accelerated training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1Ô∏è‚É£ Setup Environment\n",
    "\n",
    "Install dependencies and clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q numpy pandas scikit-learn scipy tqdm tensorboard matplotlib seaborn\n",
    "!pip install -q rdkit subword-nmt\n",
    "\n",
    "print(\"‚úì Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone repository (replace with your GitHub URL)\n",
    "import os\n",
    "\n",
    "REPO_URL = \"https://github.com/YOUR_USERNAME/drug-side-effect-prediction.git\"\n",
    "REPO_NAME = \"drug-side-effect-prediction\"\n",
    "\n",
    "# Remove existing directory if any\n",
    "if os.path.exists(REPO_NAME):\n",
    "    !rm -rf {REPO_NAME}\n",
    "\n",
    "# Clone\n",
    "!git clone {REPO_URL}\n",
    "\n",
    "# Change to repo directory\n",
    "%cd {REPO_NAME}\n",
    "\n",
    "print(\"‚úì Repository cloned!\")\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alternative_setup"
   },
   "source": [
    "### Alternative: Upload files directly\n",
    "\n",
    "If you don't have a GitHub repo, upload files manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_files"
   },
   "outputs": [],
   "source": [
    "# Uncomment to upload files manually\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# \n",
    "# # Create project structure\n",
    "# !mkdir -p data/raw data/processed\n",
    "# !mkdir -p outputs/checkpoints outputs/logs outputs/results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify"
   },
   "source": [
    "## 2Ô∏è‚É£ Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_imports"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n",
    "print(\"\\n‚úì All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_project_imports"
   },
   "outputs": [],
   "source": [
    "# Test project imports\n",
    "!python test_imports.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_data"
   },
   "source": [
    "## 3Ô∏è‚É£ Upload Data\n",
    "\n",
    "Upload your data files to `data/raw/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_data_files"
   },
   "outputs": [],
   "source": [
    "# Create directories\n",
    "!mkdir -p data/raw data/processed\n",
    "\n",
    "# Upload data files\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Please upload the following files:\")\n",
    "print(\"  1. drug_SMILES_750.csv\")\n",
    "print(\"  2. drug_codes_chembl_freq_1500.txt\")\n",
    "print(\"  3. subword_units_map_chembl_freq_1500.csv\")\n",
    "print(\"  4. drug_side.pkl\")\n",
    "print(\"\\nUploading...\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move files to data/raw\n",
    "for filename in uploaded.keys():\n",
    "    !mv {filename} data/raw/\n",
    "\n",
    "print(\"\\n‚úì Data files uploaded!\")\n",
    "!ls -lh data/raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alternative_data"
   },
   "source": [
    "### Alternative: Download from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy data from Drive (adjust paths)\n",
    "# !cp /content/drive/MyDrive/drug_data/* data/raw/\n",
    "\n",
    "print(\"‚úì Google Drive mounted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preprocess"
   },
   "source": [
    "## 4Ô∏è‚É£ Preprocess Data\n",
    "\n",
    "Extract features and create cross-validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_preprocessing"
   },
   "outputs": [],
   "source": [
    "# Run preprocessing\n",
    "!python preprocess_data.py \\\n",
    "    --data_dir data/raw \\\n",
    "    --output_dir data/processed \\\n",
    "    --top_k 50 \\\n",
    "    --n_folds 10 \\\n",
    "    --random_state 42\n",
    "\n",
    "print(\"\\n‚úì Preprocessing complete!\")\n",
    "print(\"\\nProcessed files:\")\n",
    "!ls -lh data/processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_data_stats"
   },
   "outputs": [],
   "source": [
    "# Check dataset statistics\n",
    "import json\n",
    "\n",
    "with open('data/processed/dataset_statistics.json', 'r') as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Dataset Statistics\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples:      {stats['dataset']['num_samples']:,}\")\n",
    "print(f\"Drugs:              {stats['dataset']['num_drugs']:,}\")\n",
    "print(f\"Side effects:       {stats['dataset']['num_side_effects']:,}\")\n",
    "print(f\"Positive samples:   {stats['dataset']['num_positive']:,}\")\n",
    "print(f\"Negative samples:   {stats['dataset']['num_negative']:,}\")\n",
    "print(f\"Positive ratio:     {stats['dataset']['positive_ratio']:.2%}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## 5Ô∏è‚É£ Training\n",
    "\n",
    "Train model with all optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_train"
   },
   "source": [
    "### Option A: Quick Training (1 fold, few epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_quick"
   },
   "outputs": [],
   "source": [
    "# Quick training for testing (1 fold, 10 epochs)\n",
    "!python train.py \\\n",
    "    --config fast \\\n",
    "    --epochs 10 \\\n",
    "    --batch_size 128 \\\n",
    "    --lr 1e-4 \\\n",
    "    --device cuda \\\n",
    "    --use_amp \\\n",
    "    --start_fold 0 \\\n",
    "    --end_fold 1 \\\n",
    "    --seed 42\n",
    "\n",
    "print(\"\\n‚úì Quick training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "full_train"
   },
   "source": [
    "### Option B: Full Training (10-fold CV, 200 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_full"
   },
   "outputs": [],
   "source": [
    "# Full training (WARNING: This will take 80-150 hours!)\n",
    "# Uncomment to run\n",
    "\n",
    "# !python train.py \\\n",
    "#     --config fast \\\n",
    "#     --epochs 200 \\\n",
    "#     --batch_size 128 \\\n",
    "#     --lr 1e-4 \\\n",
    "#     --device cuda \\\n",
    "#     --use_amp \\\n",
    "#     --compile_model \\\n",
    "#     --start_fold 0 \\\n",
    "#     --end_fold 10 \\\n",
    "#     --seed 42\n",
    "\n",
    "print(\"Full training configured (uncomment to run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fold_by_fold"
   },
   "source": [
    "### Option C: Train Specific Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_fold"
   },
   "outputs": [],
   "source": [
    "# Train specific fold (e.g., fold 0)\n",
    "FOLD = 0\n",
    "EPOCHS = 50\n",
    "\n",
    "!python train.py \\\n",
    "    --config fast \\\n",
    "    --epochs {EPOCHS} \\\n",
    "    --batch_size 128 \\\n",
    "    --device cuda \\\n",
    "    --use_amp \\\n",
    "    --start_fold {FOLD} \\\n",
    "    --end_fold {FOLD + 1}\n",
    "\n",
    "print(f\"\\n‚úì Fold {FOLD} training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monitor"
   },
   "source": [
    "## 6Ô∏è‚É£ Monitor Training\n",
    "\n",
    "View training progress with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tensorboard"
   },
   "outputs": [],
   "source": [
    "# Load TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard\n",
    "%tensorboard --logdir logs/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_results"
   },
   "outputs": [],
   "source": [
    "# Check training results\n",
    "import json\n",
    "\n",
    "# Load results for fold 0\n",
    "with open('outputs/results/fold_0_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Fold 0 Validation Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"RMSE:       {results['rmse']:.4f}\")\n",
    "print(f\"MAE:        {results['mae']:.4f}\")\n",
    "print(f\"Pearson:    {results['pearson']:.4f}\")\n",
    "print(f\"Spearman:   {results['spearman']:.4f}\")\n",
    "print(f\"AUC-ROC:    {results['auc_roc']:.4f}\")\n",
    "print(f\"AUC-PR:     {results['auc_pr']:.4f}\")\n",
    "print(f\"Accuracy:   {results['accuracy']:.4f}\")\n",
    "print(f\"F1-Score:   {results['f1']:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate"
   },
   "source": [
    "## 7Ô∏è‚É£ Evaluation\n",
    "\n",
    "Evaluate trained models on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_evaluation"
   },
   "outputs": [],
   "source": [
    "# Evaluate all trained folds\n",
    "!python evaluate.py \\\n",
    "    --checkpoint_dir outputs/checkpoints \\\n",
    "    --output_dir outputs \\\n",
    "    --device cuda \\\n",
    "    --save_predictions\n",
    "\n",
    "print(\"\\n‚úì Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show_test_results"
   },
   "outputs": [],
   "source": [
    "# Show test results\n",
    "import json\n",
    "\n",
    "# Load aggregated results\n",
    "with open('outputs/results/test_aggregated_results.json', 'r') as f:\n",
    "    agg_results = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Test Results (Mean ¬± Std)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metrics_to_show = [\n",
    "    'rmse', 'mae', 'pearson', 'spearman',\n",
    "    'auc_roc', 'auc_pr', 'accuracy', 'f1'\n",
    "]\n",
    "\n",
    "for metric in metrics_to_show:\n",
    "    mean_key = f\"{metric}_mean\"\n",
    "    std_key = f\"{metric}_std\"\n",
    "    \n",
    "    if mean_key in agg_results:\n",
    "        mean_val = agg_results[mean_key]\n",
    "        std_val = agg_results.get(std_key, 0)\n",
    "        print(f\"{metric:12s}: {mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize"
   },
   "source": [
    "## 8Ô∏è‚É£ Visualization\n",
    "\n",
    "Visualize predictions and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_predictions"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load predictions for fold 0\n",
    "predictions_df = pd.read_csv('outputs/results/fold_0/predictions.csv')\n",
    "\n",
    "# Plot predictions vs actual\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(predictions_df['label'], predictions_df['prediction'], \n",
    "            alpha=0.5, s=10)\n",
    "\n",
    "# Diagonal line\n",
    "min_val = min(predictions_df['label'].min(), predictions_df['prediction'].min())\n",
    "max_val = max(predictions_df['label'].max(), predictions_df['prediction'].max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "\n",
    "plt.xlabel('Actual Values', fontsize=12)\n",
    "plt.ylabel('Predicted Values', fontsize=12)\n",
    "plt.title('Predictions vs Actual (Fold 0)', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot error distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(predictions_df['error'], bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Absolute Error', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Error Distribution (Fold 0)', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 9Ô∏è‚É£ Download Results\n",
    "\n",
    "Download trained models and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zip_results"
   },
   "outputs": [],
   "source": [
    "# Zip results\n",
    "!zip -r results.zip outputs/results/\n",
    "!zip -r checkpoints.zip outputs/checkpoints/\n",
    "\n",
    "print(\"‚úì Results zipped!\")\n",
    "!ls -lh *.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_files"
   },
   "outputs": [],
   "source": [
    "# Download results\n",
    "from google.colab import files\n",
    "\n",
    "files.download('results.zip')\n",
    "files.download('checkpoints.zip')\n",
    "\n",
    "print(\"‚úì Files downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_to_drive"
   },
   "source": [
    "### Alternative: Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copy_to_drive"
   },
   "outputs": [],
   "source": [
    "# Copy to Google Drive\n",
    "!cp -r outputs/results /content/drive/MyDrive/drug_prediction_results/\n",
    "!cp -r outputs/checkpoints /content/drive/MyDrive/drug_prediction_checkpoints/\n",
    "\n",
    "print(\"‚úì Results saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference"
   },
   "source": [
    "## üîü Inference (Optional)\n",
    "\n",
    "Make predictions on new drug-side effect pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_model"
   },
   "outputs": [],
   "source": [
    "# Load trained model for inference\n",
    "import torch\n",
    "from config import get_default_config\n",
    "from model import create_model\n",
    "from smiles_encoder import create_smiles_encoder\n",
    "\n",
    "# Load config\n",
    "config = get_default_config()\n",
    "config.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Create model\n",
    "model = create_model(config.model, device=config.device)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\n",
    "    'outputs/checkpoints/fold_0/best_model.pth',\n",
    "    map_location=config.device\n",
    ")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Create SMILES encoder\n",
    "smiles_encoder = create_smiles_encoder(\n",
    "    vocab_path='data/raw/drug_codes_chembl_freq_1500.txt',\n",
    "    subword_map_path='data/raw/subword_units_map_chembl_freq_1500.csv',\n",
    "    max_len=50\n",
    ")\n",
    "\n",
    "print(\"‚úì Model loaded for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict_single"
   },
   "outputs": [],
   "source": [
    "# Make prediction on a single drug-SE pair\n",
    "import numpy as np\n",
    "\n",
    "def predict_side_effect(drug_smiles, se_id, se_index, se_mask):\n",
    "    \"\"\"\n",
    "    Predict side effect severity\n",
    "    \n",
    "    Args:\n",
    "        drug_smiles: SMILES string\n",
    "        se_id: Side effect ID\n",
    "        se_index: SE substructure indices\n",
    "        se_mask: SE substructure mask\n",
    "    \n",
    "    Returns:\n",
    "        prediction: Predicted severity score\n",
    "    \"\"\"\n",
    "    # Encode drug SMILES\n",
    "    drug_encoded, drug_mask = smiles_encoder.encode(drug_smiles)\n",
    "    \n",
    "    # Prepare inputs\n",
    "    drug_tensor = torch.from_numpy(drug_encoded).unsqueeze(0).to(config.device)\n",
    "    drug_mask_tensor = torch.from_numpy(drug_mask).unsqueeze(0).to(config.device)\n",
    "    \n",
    "    se_tensor = torch.from_numpy(se_index[se_id]).unsqueeze(0).to(config.device)\n",
    "    se_mask_tensor = torch.from_numpy(se_mask[se_id]).unsqueeze(0).to(config.device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output, _, _ = model(drug_tensor, se_tensor, drug_mask_tensor, se_mask_tensor)\n",
    "    \n",
    "    return output.item()\n",
    "\n",
    "# Example prediction\n",
    "# Load SE data\n",
    "se_index = np.load('data/processed/SE_sub_index_50_0.npy')\n",
    "se_mask = np.load('data/processed/SE_sub_mask_50_0.npy')\n",
    "\n",
    "# Example drug SMILES\n",
    "example_smiles = \"CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O\"  # Ibuprofen\n",
    "example_se_id = 0  # Side effect ID\n",
    "\n",
    "prediction = predict_side_effect(example_smiles, example_se_id, se_index, se_mask)\n",
    "\n",
    "print(f\"Drug: {example_smiles}\")\n",
    "print(f\"Side Effect ID: {example_se_id}\")\n",
    "print(f\"Predicted Severity: {prediction:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "## üí° Tips & Tricks\n",
    "\n",
    "### For Faster Training:\n",
    "1. **Use smaller batch size** if out of memory: `--batch_size 64`\n",
    "2. **Enable AMP**: `--use_amp` (already enabled)\n",
    "3. **Use fast config**: `--config fast`\n",
    "4. **Reduce epochs** for testing: `--epochs 10`\n",
    "\n",
    "### For Better Results:\n",
    "1. **Train all 10 folds** for robust evaluation\n",
    "2. **Use 200 epochs** for full training\n",
    "3. **Try different learning rates**: `--lr 1e-4` or `--lr 5e-5`\n",
    "4. **Enable torch.compile** (PyTorch 2.0+): `--compile_model`\n",
    "\n",
    "### For Memory Issues:\n",
    "1. **Use memory efficient config**: `--config memory_efficient`\n",
    "2. **Reduce batch size**: `--batch_size 32`\n",
    "3. **Enable gradient checkpointing** in config\n",
    "\n",
    "### To Resume Training:\n",
    "1. Load checkpoint in `trainer.py`\n",
    "2. Continue from last epoch\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting"
   },
   "source": [
    "## üîß Troubleshooting\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "**1. CUDA Out of Memory:**\n",
    "```bash\n",
    "# Reduce batch size\n",
    "python train.py --batch_size 32 --config memory_efficient\n",
    "```\n",
    "\n",
    "**2. Import Errors:**\n",
    "```bash\n",
    "# Verify all imports\n",
    "python test_imports.py\n",
    "```\n",
    "\n",
    "**3. Unknown Token Warnings:**\n",
    "- Normal! Limited to 10 warnings per run\n",
    "- Unknown tokens are handled gracefully\n",
    "\n",
    "**4. Slow Training:**\n",
    "- Make sure GPU is enabled: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "- Enable AMP: `--use_amp`\n",
    "- Use fast config: `--config fast`\n",
    "\n",
    "**5. Session Timeout:**\n",
    "- Colab free tier: 12 hour limit\n",
    "- Save checkpoints frequently\n",
    "- Use Google Drive to persist data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## üìù Summary\n",
    "\n",
    "### What We Did:\n",
    "1. ‚úÖ Set up environment and installed dependencies\n",
    "2. ‚úÖ Cloned/uploaded project code\n",
    "3. ‚úÖ Uploaded and preprocessed data\n",
    "4. ‚úÖ Trained drug side effect prediction model\n",
    "5. ‚úÖ Evaluated model performance\n",
    "6. ‚úÖ Visualized results\n",
    "7. ‚úÖ Downloaded/saved results\n",
    "\n",
    "### Expected Results:\n",
    "- **RMSE:** ~0.25\n",
    "- **MAE:** ~0.18\n",
    "- **Pearson:** ~0.85\n",
    "- **AUC-ROC:** ~0.95\n",
    "- **AUC-PR:** ~0.92\n",
    "\n",
    "### Next Steps:\n",
    "1. Train all 10 folds for complete evaluation\n",
    "2. Experiment with hyperparameters\n",
    "3. Try different model architectures\n",
    "4. Deploy model for inference\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Training! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
