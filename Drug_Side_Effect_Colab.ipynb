{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§¬ Drug Side Effect Prediction - Google Colab\n",
    "\n",
    "**Complete training and evaluation pipeline**\n",
    "\n",
    "---\n",
    "\n",
    "## Hardware: T4 GPU (12GB RAM minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Setup & Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Setup working directory\n",
    "!mkdir -p /content/drug_prediction\n",
    "%cd /content/drug_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy pandas scikit-learn scipy tqdm tensorboard matplotlib seaborn rdkit subword-nmt\n",
    "print(\"âœ“ Installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Upload Files\n",
    "\n",
    "Upload all `.py` files and data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "!mkdir -p data/raw\n",
    "\n",
    "print(\"Upload: data files + all .py files\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move data files\n",
    "for f in uploaded.keys():\n",
    "    if f.endswith(('.pkl', '.csv', '.txt')):\n",
    "        !mv \"{f}\" data/raw/\n",
    "        \n",
    "print(\"âœ“ Uploaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Verify Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check data\n",
    "data_files = ['drug_SMILES_750.csv', 'drug_codes_chembl_freq_1500.txt', \n",
    "              'subword_units_map_chembl_freq_1500.csv', 'drug_side.pkl']\n",
    "\n",
    "print(\"Data Files:\")\n",
    "for f in data_files:\n",
    "    path = f'data/raw/{f}'\n",
    "    print(f\"{'âœ“' if os.path.exists(path) else 'âœ—'} {f}\")\n",
    "\n",
    "# Check code\n",
    "code_files = ['config.py', 'dataset.py', 'encoder.py', 'model.py', \n",
    "              'smiles_encoder.py', 'preprocessing.py', 'preprocess_data.py',\n",
    "              'trainer.py', 'evaluator.py', 'train.py', 'evaluate.py']\n",
    "\n",
    "print(\"\\nCode Files:\")\n",
    "for f in code_files:\n",
    "    print(f\"{'âœ“' if os.path.exists(f) else 'âœ—'} {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Preprocess Data (20-30 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess_data.py \\\n",
    "    --data_dir data/raw \\\n",
    "    --output_dir data/processed \\\n",
    "    --top_k 50 \\\n",
    "    --n_folds 10\n",
    "\n",
    "print(\"\\nâœ“ Preprocessing done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View statistics\n",
    "import json\n",
    "with open('data/processed/dataset_statistics.json') as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "print(f\"Samples: {stats['dataset']['num_samples']:,}\")\n",
    "print(f\"Positive: {stats['dataset']['num_positive']:,}\")\n",
    "print(f\"Drugs: {stats['dataset']['num_drugs']:,}\")\n",
    "print(f\"Side Effects: {stats['dataset']['num_side_effects']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Train Model\n",
    "\n",
    "### Quick Test (1 fold, 50 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "    --config fast \\\n",
    "    --start_fold 0 \\\n",
    "    --end_fold 1 \\\n",
    "    --epochs 50 \\\n",
    "    --batch_size 128 \\\n",
    "    --use_amp \\\n",
    "    --device cuda\n",
    "\n",
    "print(\"\\nâœ“ Training done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Training (10 folds, 200 epochs) - Takes 20-30 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run full training\n",
    "# !python train.py \\\n",
    "#     --config fast \\\n",
    "#     --epochs 200 \\\n",
    "#     --batch_size 128 \\\n",
    "#     --use_amp \\\n",
    "#     --compile_model \\\n",
    "#     --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate.py \\\n",
    "    --checkpoint_dir checkpoints \\\n",
    "    --save_predictions \\\n",
    "    --device cuda\n",
    "\n",
    "print(\"\\nâœ“ Evaluation done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "with open('outputs/results/test_aggregated_results.json') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "for metric in ['rmse', 'pearson', 'auc_roc', 'f1']:\n",
    "    mean = results.get(f'{metric}_mean', 0)\n",
    "    std = results.get(f'{metric}_std', 0)\n",
    "    print(f\"{metric:10s}: {mean:.4f} Â± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Load predictions\n",
    "df = pd.read_csv('outputs/results/fold_0/predictions.csv')\n",
    "y_true = df['label'].values\n",
    "y_pred = df['prediction'].values\n",
    "\n",
    "# Create plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_true, y_pred, alpha=0.3, s=10)\n",
    "axes[0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n",
    "corr, _ = pearsonr(y_true, y_pred)\n",
    "axes[0].set_title(f'Predictions\\nPearson: {corr:.3f}')\n",
    "axes[0].set_xlabel('Actual')\n",
    "axes[0].set_ylabel('Predicted')\n",
    "\n",
    "# ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_true_bin = (y_true != 0).astype(int)\n",
    "fpr, tpr, _ = roc_curve(y_true_bin, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes[1].plot(fpr, tpr, label=f'AUC = {roc_auc:.3f}')\n",
    "axes[1].plot([0, 1], [0, 1], 'r--')\n",
    "axes[1].set_title('ROC Curve')\n",
    "axes[1].set_xlabel('FPR')\n",
    "axes[1].set_ylabel('TPR')\n",
    "axes[1].legend()\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "cm = confusion_matrix(y_true_bin, y_pred_bin)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[2])\n",
    "axes[2].set_title('Confusion Matrix')\n",
    "axes[2].set_xlabel('Predicted')\n",
    "axes[2].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results_visualization.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip results\n",
    "!zip -r results.zip outputs/results/\n",
    "!zip -r checkpoints.zip checkpoints/fold_0/best_model.pth\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download('results.zip')\n",
    "files.download('checkpoints.zip')\n",
    "\n",
    "print(\"âœ“ Downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”Ÿ Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for inference\n",
    "from config import get_default_config\n",
    "from model import create_model\n",
    "from smiles_encoder import create_smiles_encoder\n",
    "\n",
    "# Setup\n",
    "config = get_default_config()\n",
    "config.device = 'cuda'\n",
    "\n",
    "model = create_model(config.model, device='cuda')\n",
    "checkpoint = torch.load('checkpoints/fold_0/best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "smiles_encoder = create_smiles_encoder(\n",
    "    'data/raw/drug_codes_chembl_freq_1500.txt',\n",
    "    'data/raw/subword_units_map_chembl_freq_1500.csv',\n",
    "    50\n",
    ")\n",
    "\n",
    "se_index = np.load('data/processed/SE_sub_index_50_0.npy')\n",
    "se_mask = np.load('data/processed/SE_sub_mask_50_0.npy')\n",
    "\n",
    "print(\"âœ“ Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "@torch.no_grad()\n",
    "def predict(drug_smiles, se_id):\n",
    "    drug_enc, drug_m = smiles_encoder.encode(drug_smiles)\n",
    "    se_enc = se_index[se_id]\n",
    "    se_m = se_mask[se_id]\n",
    "    \n",
    "    drug_t = torch.from_numpy(drug_enc).unsqueeze(0).cuda()\n",
    "    se_t = torch.from_numpy(se_enc).unsqueeze(0).cuda()\n",
    "    drug_m_t = torch.from_numpy(drug_m).unsqueeze(0).cuda()\n",
    "    se_m_t = torch.from_numpy(se_m).unsqueeze(0).cuda()\n",
    "    \n",
    "    output, _, _ = model(drug_t, se_t, drug_m_t, se_m_t)\n",
    "    return output.item()\n",
    "\n",
    "# Example\n",
    "smiles = \"CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O\"  # Ibuprofen\n",
    "se_id = 100\n",
    "\n",
    "pred = predict(smiles, se_id)\n",
    "print(f\"\\nDrug: {smiles}\")\n",
    "print(f\"SE ID: {se_id}\")\n",
    "print(f\"Prediction: {pred:.4f}\")\n",
    "print(f\"Has SE: {'Yes' if pred > 0.5 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Complete!\n",
    "\n",
    "**Your model is trained and ready to use!** ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
